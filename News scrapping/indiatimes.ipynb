{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\yogev\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yogev\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: requests in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\yogev\\appdata\\roaming\\python\\python39\\site-packages (from webdriver_manager) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yogev\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (3.8)\n",
      "Requirement already satisfied: outcome in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\yogev\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\yogev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium bs4 beautifulsoup4 pandas webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=128.0.6613.85)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00718283+26163]\n",
      "\t(No symbol) [0x006A9D34]\n",
      "\t(No symbol) [0x005A24C3]\n",
      "\t(No symbol) [0x0057E27B]\n",
      "\t(No symbol) [0x0061192F]\n",
      "\t(No symbol) [0x00623F99]\n",
      "\t(No symbol) [0x0060AA56]\n",
      "\t(No symbol) [0x005DBE89]\n",
      "\t(No symbol) [0x005DC8CD]\n",
      "\tGetHandleVerifier [0x009ECF73+2994979]\n",
      "\tGetHandleVerifier [0x00A417E9+3341209]\n",
      "\tGetHandleVerifier [0x007A7B5F+614159]\n",
      "\tGetHandleVerifier [0x007AF1EC+644508]\n",
      "\t(No symbol) [0x006B286D]\n",
      "\t(No symbol) [0x006AF768]\n",
      "\t(No symbol) [0x006AF905]\n",
      "\t(No symbol) [0x006A1C86]\n",
      "\tBaseThreadInitThunk [0x76A67BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x77A2C11B+107]\n",
      "\tRtlClearBits [0x77A2C09F+191]\n",
      "\n",
      "                                               Title  \\\n",
      "0  Growing real estate sector can give a boost to...   \n",
      "1  KPI Green Energy gets LoIs for 13.30 MW green ...   \n",
      "2  India's green energy wind drive hits desert he...   \n",
      "3  Domestic banks and NBFCs increase exposure to ...   \n",
      "4  'Reliance's capex pace in its new energy biz s...   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://economictimes.indiatimes.com/small-biz...   \n",
      "1  https://economictimes.indiatimes.com/industry/...   \n",
      "2  https://economictimes.indiatimes.com/industry/...   \n",
      "3  https://economictimes.indiatimes.com/industry/...   \n",
      "4  https://economictimes.indiatimes.com/news/comp...   \n",
      "\n",
      "                                         Description  \\\n",
      "0  The green building market in India generated $...   \n",
      "1  KPI Green Energy has received Letters of Inten...   \n",
      "2  Whirring wind turbines in India's Thar desert ...   \n",
      "3  Domestic banks and non-banking financial compa...   \n",
      "4  Reliance Industries' new energy venture, initi...   \n",
      "\n",
      "                         Time  \n",
      "0  27 Aug, 2024, 10:43 AM IST  \n",
      "1  26 Aug, 2024, 05:22 PM IST  \n",
      "2  26 Aug, 2024, 10:01 AM IST  \n",
      "3  26 Aug, 2024, 12:11 AM IST  \n",
      "4  24 Aug, 2024, 01:03 AM IST  \n",
      "Data saved to green_energy_articles_max_articles_max_date8379_articles.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Function to get topic from the user\n",
    "def get_topic_url(topic):\n",
    "    base_url = \"https://economictimes.indiatimes.com/topic/\"\n",
    "    topic_url = base_url + topic.replace(\" \", \"-\") + \"/news\"\n",
    "    return topic_url\n",
    "\n",
    "# Get topic from the user\n",
    "topic = input(\"Enter the topic to scrape: \")\n",
    "url = get_topic_url(topic)\n",
    "\n",
    "# Set up conditions\n",
    "max_articles = input(\"Enter the maximum number of articles to scrape (leave blank for no limit): \")\n",
    "max_articles = int(max_articles) if max_articles else None\n",
    "\n",
    "max_date_str = input(\"Enter the latest date to scrape articles (in format YYYY-MM-DD, leave blank for no limit): \")\n",
    "max_date = datetime.strptime(max_date_str, \"%Y-%m-%d\") if max_date_str else None\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.get(url)\n",
    "\n",
    "# Initialize a list to store the scraped data\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    # Scroll and click \"Load More\" until no more content is loaded\n",
    "    while True:\n",
    "        # Parse the HTML content of the webpage\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Find all article elements\n",
    "        articles = soup.find_all(\"div\", class_=\"clr flt topicstry story_list\")\n",
    "\n",
    "        # Extract data from each article element\n",
    "        for article in articles:\n",
    "            # Find the title and link\n",
    "            title_tag = article.find(\"h2\").find(\"a\")\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            link = \"https://economictimes.indiatimes.com\" + title_tag[\"href\"]\n",
    "\n",
    "            # Find the description\n",
    "            description_tag = article.find(\"p\", class_=\"wrapLines l3\")\n",
    "            description = description_tag.get_text(strip=True) if description_tag else \"No description\"\n",
    "\n",
    "            # Find the time of publication\n",
    "            time_tag = article.find(\"time\")\n",
    "            time_value = time_tag.get_text(strip=True) if time_tag else \"No time\"\n",
    "            article_date = datetime.strptime(time_value, \"%d %b, %Y, %I:%M %p IST\") if time_tag else None\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            data.append({\n",
    "                \"Title\": title,\n",
    "                \"Link\": link,\n",
    "                \"Description\": description,\n",
    "                \"Time\": time_value\n",
    "            })\n",
    "\n",
    "            # Check the conditions\n",
    "            if max_articles and len(data) >= max_articles:\n",
    "                break\n",
    "            if max_date and article_date and article_date < max_date:\n",
    "                break\n",
    "\n",
    "        # Check the conditions after processing the articles\n",
    "        if max_articles and len(data) >= max_articles:\n",
    "            break\n",
    "        if max_date and article_date and article_date < max_date:\n",
    "            break\n",
    "        \n",
    "        # Scroll all the way to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # wait for the page to load new content\n",
    "\n",
    "        # Try to click the \"Load More\" button using JavaScript\n",
    "        try:\n",
    "            load_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'jsTopicLoadMore'))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "            time.sleep(3)  # wait for new content to load\n",
    "        except:\n",
    "            print(\"No more 'Load More' button found or it could not be clicked. Stopping the scroll.\")\n",
    "            break  # no more \"Load More\" button, exit loop\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "    # Construct the filename\n",
    "    filename = f\"{topic.replace(' ', '_')}_articles\"\n",
    "    if max_articles:\n",
    "        filename += f\"_max{max_articles}\"\n",
    "    else:\n",
    "        filename += f\"_max_articles\"\n",
    "    if max_date:\n",
    "        filename += f\"_end{max_date.strftime('%Y%m%d')}\"\n",
    "    else:\n",
    "        filename += f\"_max_date\"\n",
    "        filename += f\"_{df.shape[0]}_articles\"\n",
    "    filename += \".csv\"\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
<<<<<<< HEAD
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")"
=======
    "    save_path = os.path.join(\"datasets\", \"scrapped_news_data\", filename)\n",
    "    df.to_csv(save_path, index=False)"
>>>>>>> e3d630a9816aa78e66dc6458a0f96f4390f4be91
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
