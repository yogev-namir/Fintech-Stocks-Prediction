{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium bs4 beautifulsoup4 pandas webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: Chrome failed to start: was killed.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location chromedriver.exe is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n\tGetHandleVerifier [0x01188923+23283]\n\t(No symbol) [0x0114E934]\n\t(No symbol) [0x01080733]\n\t(No symbol) [0x010B1075]\n\t(No symbol) [0x010ABAE9]\n\t(No symbol) [0x010ED9ED]\n\t(No symbol) [0x010ED21A]\n\t(No symbol) [0x010E41B6]\n\t(No symbol) [0x010B8017]\n\t(No symbol) [0x010B890D]\n\tGetHandleVerifier [0x0127A5E3+1013683]\n\tGetHandleVerifier [0x01283E3C+1052684]\n\tGetHandleVerifier [0x0127D4A4+1025652]\n\tGetHandleVerifier [0x011AEA2B+179195]\n\t(No symbol) [0x01156833]\n\t(No symbol) [0x01153198]\n\t(No symbol) [0x01153337]\n\t(No symbol) [0x0114B4BE]\n\tBaseThreadInitThunk [0x7712FCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x774D80CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x774D809E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# service = Service(ChromeDriverManager().install())\u001b[39;00m\n\u001b[0;32m     36\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(ChromeDriverManager()\u001b[38;5;241m.\u001b[39minstall())\n\u001b[1;32m---> 37\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:66\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:212\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_websocket_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:299\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[1;32m--> 299\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaps\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: Chrome failed to start: was killed.\n  (session not created: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location chromedriver.exe is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n\tGetHandleVerifier [0x01188923+23283]\n\t(No symbol) [0x0114E934]\n\t(No symbol) [0x01080733]\n\t(No symbol) [0x010B1075]\n\t(No symbol) [0x010ABAE9]\n\t(No symbol) [0x010ED9ED]\n\t(No symbol) [0x010ED21A]\n\t(No symbol) [0x010E41B6]\n\t(No symbol) [0x010B8017]\n\t(No symbol) [0x010B890D]\n\tGetHandleVerifier [0x0127A5E3+1013683]\n\tGetHandleVerifier [0x01283E3C+1052684]\n\tGetHandleVerifier [0x0127D4A4+1025652]\n\tGetHandleVerifier [0x011AEA2B+179195]\n\t(No symbol) [0x01156833]\n\t(No symbol) [0x01153198]\n\t(No symbol) [0x01153337]\n\t(No symbol) [0x0114B4BE]\n\tBaseThreadInitThunk [0x7712FCC9+25]\n\tRtlGetAppContainerNamedObjectPath [0x774D80CE+286]\n\tRtlGetAppContainerNamedObjectPath [0x774D809E+238]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Function to get topic from the user\n",
    "def get_topic_url(topic):\n",
    "    base_url = \"https://economictimes.indiatimes.com/topic/\"\n",
    "    topic_url = base_url + topic.replace(\" \", \"-\") + \"/news\"\n",
    "    return topic_url\n",
    "\n",
    "# Get topic from the user\n",
    "topic = input(\"Enter the topic to scrape: \")\n",
    "url = get_topic_url(topic)\n",
    "\n",
    "# Set up conditions\n",
    "max_articles = input(\"Enter the maximum number of articles to scrape (leave blank for no limit): \")\n",
    "max_articles = int(max_articles) if max_articles else None\n",
    "\n",
    "max_date_str = input(\"Enter the latest date to scrape articles (in format YYYY-MM-DD, leave blank for no limit): \")\n",
    "max_date = datetime.strptime(max_date_str, \"%Y-%m-%d\") if max_date_str else None\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = Options()\n",
    "options.binary_location = \"chromedriver.exe\"  # Provide the correct path to your Chrome binary\n",
    "\n",
    "# service = Service(ChromeDriverManager().install())\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'driver' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Close the driver\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Convert the data into a DataFrame\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the scraped data\n",
    "data = []\n",
    "scraped_links = set()  # To keep track of scraped links\n",
    "\n",
    "def extract_articles(articles):\n",
    "    for article in articles:\n",
    "        try:\n",
    "            # Find the title and link\n",
    "            title_tag = article.find(\"h2\")\n",
    "            if title_tag:\n",
    "                title = title_tag.get_text(strip=True)\n",
    "                link_tag = article.find(\"a\")\n",
    "                link = link_tag[\"href\"] if link_tag else None\n",
    "            else:\n",
    "                # Handle articles in the container\n",
    "                link_tag = article.find(\"a\", itemprop=\"url\")\n",
    "                if not link_tag:\n",
    "                    continue\n",
    "                title = link_tag.get(\"title\", link_tag.find(\"meta\", itemprop=\"name\")[\"content\"])\n",
    "                link = link_tag[\"href\"]\n",
    "            \n",
    "            if not link.startswith(\"http\"):\n",
    "                link = \"https://economictimes.indiatimes.com\" + link\n",
    "\n",
    "            # Skip if the article has already been scraped\n",
    "            if link in scraped_links:\n",
    "                continue\n",
    "            scraped_links.add(link)\n",
    "\n",
    "            # Find the description\n",
    "            description_tag = article.find(\"p\", class_=\"wrapLines l3\") or article.find(\"div\", class_=\"wrapLines l4\")\n",
    "            description = description_tag.get_text(strip=True) if description_tag else \"No description\"\n",
    "\n",
    "            # Find the date of publication\n",
    "            time_tag = article.find(\"time\")\n",
    "            time_value = time_tag.get_text(strip=True) if time_tag else \"No time\"\n",
    "            date_parts = time_value.split(\",\")[:2]  # Get the date part only (day, month, year)\n",
    "            date_value = \",\".join(date_parts).strip()\n",
    "\n",
    "            article_date = datetime.strptime(date_value, \"%d %b, %Y\") if time_tag else None\n",
    "            formatted_date = article_date.strftime(\"%Y-%m-%d\") if article_date else \"No date\"\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            data.append({\n",
    "                \"Title\": title,\n",
    "                \"Link\": link,\n",
    "                \"Description\": description,\n",
    "                \"Date\": formatted_date\n",
    "            })\n",
    "\n",
    "            # Check the conditions\n",
    "            if max_articles and len(data) >= max_articles:\n",
    "                return True\n",
    "            if max_date and article_date and article_date < max_date:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting article: {e}\")\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "try:\n",
    "    # Initial parse to get the first set of articles\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    initial_articles = soup.find_all(\"div\", class_=\"clr flt topicstry story_list\")\n",
    "    print(f\"Found {len(initial_articles)} initial articles.\")\n",
    "    if extract_articles(initial_articles):\n",
    "        raise StopIteration\n",
    "\n",
    "    # Scroll and click \"Load More\" until no more content is loaded\n",
    "    while True:\n",
    "        # Scroll all the way to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # wait for the page to load new content\n",
    "\n",
    "        # Try to click the \"Load More\" button using JavaScript\n",
    "        try:\n",
    "            load_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'jsTopicLoadMore'))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "            time.sleep(3)  # wait for new content to load\n",
    "        except:\n",
    "            print(\"No more 'Load More' button found or it could not be clicked. Stopping the scroll.\")\n",
    "            break  # no more \"Load More\" button, exit loop\n",
    "\n",
    "        # Parse the new content\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Find all new article containers\n",
    "        more_stories = soup.find_all(\"div\", class_=\"moreStories\")\n",
    "        print(f\"Found {len(more_stories)} 'moreStories' containers on the current page.\")\n",
    "\n",
    "        # Extract data from each article element within new containers\n",
    "        for container in more_stories:\n",
    "            articles = container.find_all(\"div\", class_=\"clr flt topicstry\")\n",
    "            print(f\"Found {len(articles)} articles in the current 'moreStories' container.\")\n",
    "            if extract_articles(articles):\n",
    "                raise StopIteration\n",
    "\n",
    "except StopIteration:\n",
    "    print(\"Stopping the scraping process as conditions were met.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "    # Construct the filename\n",
    "    filename = f\"{topic.replace(' ', '_')}_articles\"\n",
    "    if max_articles:\n",
    "        filename += f\"_max{max_articles}\"\n",
    "    if max_date:\n",
    "        filename += f\"_end{max_date.strftime('%Y%m%d')}\"\n",
    "    filename += \".csv\"\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    save_path = os.path.join(\"datasets\", \"scrapped_news_data\", filename)\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
