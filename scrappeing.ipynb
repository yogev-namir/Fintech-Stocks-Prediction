{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user\\miniconda3\\lib\\site-packages (4.22.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\user\\miniconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\miniconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\miniconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\miniconda3\\lib\\site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\miniconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client>=1.8.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\miniconda3\\lib\\site-packages (from webdriver_manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from webdriver_manager) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\miniconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\miniconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\miniconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver_manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium bs4 beautifulsoup4 pandas webdriver_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=126.0.6478.127)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00D8C1C3+27395]\n",
      "\t(No symbol) [0x00D23DC4]\n",
      "\t(No symbol) [0x00C21B7F]\n",
      "\t(No symbol) [0x00C0C8E8]\n",
      "\t(No symbol) [0x00C0C809]\n",
      "\t(No symbol) [0x00C23DB0]\n",
      "\t(No symbol) [0x00C9C3F6]\n",
      "\t(No symbol) [0x00C83736]\n",
      "\t(No symbol) [0x00C57541]\n",
      "\t(No symbol) [0x00C580BD]\n",
      "\tGetHandleVerifier [0x01043A93+2876371]\n",
      "\tGetHandleVerifier [0x01097F5D+3221661]\n",
      "\tGetHandleVerifier [0x00E0D634+556916]\n",
      "\tGetHandleVerifier [0x00E1474C+585868]\n",
      "\t(No symbol) [0x00D2CE04]\n",
      "\t(No symbol) [0x00D29818]\n",
      "\t(No symbol) [0x00D299B7]\n",
      "\t(No symbol) [0x00D1BF0E]\n",
      "\tBaseThreadInitThunk [0x76FEFCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778A80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778A809E+238]\n",
      "\n",
      "                                               Title  \\\n",
      "0  NexGen Energia plans to invest Rs 15,000 cr ov...   \n",
      "1  JSW Energy plans â‚¹1.15 L cr capex to diversify...   \n",
      "2  Interest subvention likely to push energy effi...   \n",
      "3  MNRE issues incentive guidelines for green hyd...   \n",
      "4  Norms issued for funding of testing facilities...   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://economictimes.indiatimes.com/industry/...   \n",
      "1  https://economictimes.indiatimes.com/industry/...   \n",
      "2  https://economictimes.indiatimes.com/industry/...   \n",
      "3  https://economictimes.indiatimes.com/industry/...   \n",
      "4  https://economictimes.indiatimes.com/industry/...   \n",
      "\n",
      "                                         Description  \\\n",
      "0  NexGen Energia plans a Rs 15,000 crore investm...   \n",
      "1  JSW Energy announces a strategic shift towards...   \n",
      "2  The power ministry has begun discussions on of...   \n",
      "3  Solar Energy Corporation of India (SECI) is th...   \n",
      "4  The Ministry of New and Renewable Energy has r...   \n",
      "\n",
      "                         Time  \n",
      "0  07 Jul, 2024, 01:52 PM IST  \n",
      "1  06 Jul, 2024, 12:35 AM IST  \n",
      "2  05 Jul, 2024, 11:45 PM IST  \n",
      "3  05 Jul, 2024, 05:29 PM IST  \n",
      "4  05 Jul, 2024, 12:41 AM IST  \n",
      "Data saved to green_energy_articles_max_articles_end20220101.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Function to get topic from the user\n",
    "def get_topic_url(topic):\n",
    "    base_url = \"https://economictimes.indiatimes.com/topic/\"\n",
    "    topic_url = base_url + topic.replace(\" \", \"-\") + \"/news\"\n",
    "    return topic_url\n",
    "\n",
    "# Get topic from the user\n",
    "topic = input(\"Enter the topic to scrape: \")\n",
    "url = get_topic_url(topic)\n",
    "\n",
    "# Set up conditions\n",
    "max_articles = input(\"Enter the maximum number of articles to scrape (leave blank for no limit): \")\n",
    "max_articles = int(max_articles) if max_articles else None\n",
    "\n",
    "max_date_str = input(\"Enter the latest date to scrape articles (in format YYYY-MM-DD, leave blank for no limit): \")\n",
    "max_date = datetime.strptime(max_date_str, \"%Y-%m-%d\") if max_date_str else None\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.get(url)\n",
    "\n",
    "# Initialize a list to store the scraped data\n",
    "data = []\n",
    "\n",
    "try:\n",
    "    # Scroll and click \"Load More\" until no more content is loaded\n",
    "    while True:\n",
    "        # Parse the HTML content of the webpage\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Find all article elements\n",
    "        articles = soup.find_all(\"div\", class_=\"clr flt topicstry story_list\")\n",
    "\n",
    "        # Extract data from each article element\n",
    "        for article in articles:\n",
    "            # Find the title and link\n",
    "            title_tag = article.find(\"h2\").find(\"a\")\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            link = \"https://economictimes.indiatimes.com\" + title_tag[\"href\"]\n",
    "\n",
    "            # Find the description\n",
    "            description_tag = article.find(\"p\", class_=\"wrapLines l3\")\n",
    "            description = description_tag.get_text(strip=True) if description_tag else \"No description\"\n",
    "\n",
    "            # Find the time of publication\n",
    "            time_tag = article.find(\"time\")\n",
    "            time_value = time_tag.get_text(strip=True) if time_tag else \"No time\"\n",
    "            article_date = datetime.strptime(time_value, \"%d %b, %Y, %I:%M %p IST\") if time_tag else None\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            data.append({\n",
    "                \"Title\": title,\n",
    "                \"Link\": link,\n",
    "                \"Description\": description,\n",
    "                \"Time\": time_value\n",
    "            })\n",
    "\n",
    "            # Check the conditions\n",
    "            if max_articles and len(data) >= max_articles:\n",
    "                break\n",
    "            if max_date and article_date and article_date < max_date:\n",
    "                break\n",
    "\n",
    "        # Check the conditions after processing the articles\n",
    "        if max_articles and len(data) >= max_articles:\n",
    "            break\n",
    "        if max_date and article_date and article_date < max_date:\n",
    "            break\n",
    "        \n",
    "        # Scroll all the way to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # wait for the page to load new content\n",
    "\n",
    "        # Try to click the \"Load More\" button using JavaScript\n",
    "        try:\n",
    "            load_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'jsTopicLoadMore'))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "            time.sleep(3)  # wait for new content to load\n",
    "        except:\n",
    "            print(\"No more 'Load More' button found or it could not be clicked. Stopping the scroll.\")\n",
    "            break  # no more \"Load More\" button, exit loop\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "    # Construct the filename\n",
    "    filename = f\"{topic.replace(' ', '_')}_articles\"\n",
    "    if max_articles:\n",
    "        filename += f\"_max{max_articles}\"\n",
    "    else:\n",
    "        filename += f\"_max_articles\"\n",
    "    if max_date:\n",
    "        filename += f\"_end{max_date.strftime('%Y%m%d')}\"\n",
    "    else:\n",
    "        filename += f\"_max_date\"\n",
    "    filename += \".csv\"\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Data saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
